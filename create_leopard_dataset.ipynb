{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371a2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import os\n",
    "import numpy\n",
    "#from utils import create_yolo_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6d8b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 6795/6795 [11.1s elapsed, 0s remaining, 653.6 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# The directory containing the source images\n",
    "data_path = \"../leopard/leopard_coco/images/train2022/\"\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"../leopard/leopard_coco/annotations/instances_train2022.json\"\n",
    "\n",
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=data_path,\n",
    "    labels_path=labels_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e96ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Creates YOLOV4 dataset\n",
    "# Data split into train and test \n",
    "# train set in images/train_2022/ and test in /images/test_2022\n",
    "# train files in ./data/train.txt and test files in ./data/test.txt\n",
    "\n",
    "def create_yolo_dataset(dataset, train_test_split = 0.8, output_folder='./'):\n",
    "    anno = [0, 0, 0, 0, 0]\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "\n",
    "    count = 0\n",
    "                       \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_image_path =  output_folder+'/data/obj'                   \n",
    "    isExist = os.path.exists(train_image_path)                  \n",
    "                    \n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(train_image_path)    \n",
    "                        \n",
    "    test_image_path =  output_folder+'/images/test'                       \n",
    "    isExist = os.path.exists(test_image_path)\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(test_image_path)                    \n",
    "\n",
    "    for sample in dataset:  \n",
    "        old_image_file = sample['filepath']\n",
    "        train_image_file = 'data/obj/' + old_image_file.split(\"/\")[-1]\n",
    "        new_image_file = output_folder + '/images/test/' + old_image_file.split(\"/\")[-1]                \n",
    "        \n",
    "        if count > 10:\n",
    "            break\n",
    "        count = count + 1  \n",
    "        \n",
    "        if(np.random.random_sample() > train_test_split):        \n",
    "            test_files.append(new_image_file+'\\n')\n",
    "        else:\n",
    "            train_files.append(train_image_file+'\\n')\n",
    "            new_image_file =  output_folder+'/'+ train_image_file    \n",
    "                        \n",
    "        new_anno_file = new_image_file.replace(\"jpg\", \"txt\")              \n",
    "           \n",
    "        copy_str = 'cp ' + old_image_file + ' ' + new_image_file\n",
    "        os.system(copy_str)\n",
    "        \n",
    "        anno[1:] = sample['ground_truth']['detections'][0]['bounding_box']\n",
    "        with open(new_anno_file, 'w') as fp:\n",
    "            for item in anno:\n",
    "            # write each item on a new line\n",
    "                fp.write(\"%s \" % item)\n",
    "            fp.write(\"\\n\")  \n",
    "    \n",
    "    print(train_files)                     \n",
    "    print(test_files)         \n",
    "    with open(output_folder+'/data/test.txt', 'w') as fp:\n",
    "        fp.writelines(test_files)         \n",
    "    with open(output_folder+'/data/train.txt', 'w') as fp:\n",
    "        fp.writelines(train_files)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337b316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/obj/000000000001.jpg\\n', 'data/obj/000000000003.jpg\\n', 'data/obj/000000000004.jpg\\n', 'data/obj/000000000005.jpg\\n', 'data/obj/000000000006.jpg\\n', 'data/obj/000000000007.jpg\\n', 'data/obj/000000000009.jpg\\n', 'data/obj/000000000010.jpg\\n', 'data/obj/000000000011.jpg\\n']\n",
      "['/Users/madhuhegde/work/berkeley/W210/leopard_identification/images/test/000000000002.jpg\\n', '/Users/madhuhegde/work/berkeley/W210/leopard_identification/images/test/000000000008.jpg\\n']\n"
     ]
    }
   ],
   "source": [
    "#create_yolo_dataset(dataset, output_file_path=\"/home/user1/work/darknet/yolov4/darknet/data\")\n",
    "create_yolo_dataset(dataset, output_folder=\"/Users/madhuhegde/work/berkeley/W210/leopard_identification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d000cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyOne_env",
   "language": "python",
   "name": "fiftyone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
