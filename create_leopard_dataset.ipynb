{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import os\n",
    "import numpy\n",
    "from utils import create_yolo_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory containing the source images\n",
    "data_path = \"~/Downloads/leopard.coco/images/train2022/\"\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"~/Downloads/leopard.coco/annotations/instances_train2022.json\"\n",
    "\n",
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=data_path,\n",
    "    labels_path=labels_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411dd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_dataset(dataset, output_folder=\"/home/user1/work/darknet/yolov4/darknet\")\n",
    "#create_yolo_dataset(dataset, output_folder=\"/Users/madhuhegde/work/berkeley/W210/leopard_identification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d000cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Creates YOLOV4 dataset\n",
    "# Data split into train and test \n",
    "# train set in images/train_2022/ and test in /images/test_2022\n",
    "# train files in ./data/train.txt and test files in ./data/test.txt\n",
    "\n",
    "def create_yolo_dataset(dataset, train_test_split = 0.8, output_folder='./'):\n",
    "    anno = [0, 0, 0, 0, 0]\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "       \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_image_path =  output_folder+'/data/obj'                   \n",
    "    isExist = os.path.exists(train_image_path)                  \n",
    "                    \n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(train_image_path)    \n",
    "                        \n",
    "    test_image_path =  output_folder+'/images/test'                       \n",
    "    isExist = os.path.exists(test_image_path)\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(test_image_path)                    \n",
    "\n",
    "    for sample in dataset:  \n",
    "        anno[1:] = sample['ground_truth']['detections'][0]['bounding_box']\n",
    "        height = sample['metadata']['height']\n",
    "        width = sample['metadata']['width']\n",
    "        if anno[1] <=0:\n",
    "            anno[1] = 1.0/width\n",
    "            \n",
    "        if anno[2] <=0:\n",
    "            anno[2] = 1.0/height\n",
    "            \n",
    "        if anno[3] >=1.0:\n",
    "            anno[3] = 1-1.0/width\n",
    "            \n",
    "        if anno[4] >=1.0:\n",
    "            anno[4] = 1-1.0/height    \n",
    "       \n",
    "       \n",
    "            \n",
    "        old_image_file = sample['filepath']\n",
    "        train_image_file = 'data/obj/' + old_image_file.split(\"/\")[-1]\n",
    "        new_image_file = output_folder + '/images/test/' + old_image_file.split(\"/\")[-1]                 \n",
    "        \n",
    "        if(np.random.random_sample() > train_test_split):        \n",
    "            test_files.append(new_image_file+'\\n')\n",
    "        else:\n",
    "            train_files.append(train_image_file+'\\n')\n",
    "            new_image_file =  output_folder+'/'+ train_image_file    \n",
    "                        \n",
    "        new_anno_file = new_image_file.replace(\"jpg\", \"txt\")              \n",
    "           \n",
    "        copy_str = 'cp ' + old_image_file + ' ' + new_image_file\n",
    "        os.system(copy_str)\n",
    "        \n",
    "        with open(new_anno_file, 'w') as fp:\n",
    "            for item in anno:\n",
    "            # write each item on a new line\n",
    "                fp.write(\"%s \" % item)\n",
    "            fp.write(\"\\n\")  \n",
    "    \n",
    "   \n",
    "    with open(output_folder+'/data/test.txt', 'w') as fp:\n",
    "        fp.writelines(test_files)         \n",
    "    with open(output_folder+'/data/train.txt', 'w') as fp:\n",
    "        fp.writelines(train_files)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c206bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w210_env",
   "language": "python",
   "name": "w210_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
